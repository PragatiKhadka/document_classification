{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics\n",
    "# Sklearn regression model evaluation function\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('augmented_text_red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_character_remover = re.compile('[/(){}\\[\\]\\|@,;:]')\n",
    "extra_symbol_remover = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = nltk.corpus.stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #text = text.lower()\n",
    "    text = special_character_remover.sub(' ', text)\n",
    "    text = extra_symbol_remover.sub('', text)\n",
    "    text = ''.join(c for c in text if not c.isdigit())\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='text', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={\"label2\": \"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.text\n",
    "y = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bay Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "naivebayes = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "naivebayes.fit(X_train, y_train)\n",
    "\n",
    "predictions_NB = naivebayes.predict(X_test)\n",
    "\n",
    "print(\"Naive Bay Accuracy Score -> \",accuracy_score(predictions_NB,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes Classification Report\", classification_report(y_test, predictions_NB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "lr = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', LogisticRegression()),\n",
    "              ])\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "predictions_LR = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic regression Accuracy Score -> \",accuracy_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Classification Report\", classification_report(y_test, predictions_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "\n",
    "SVM = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('svm',svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')),\n",
    "              ])\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predictions_SVM)\n",
    "report_path = \"SVM_report.csv\"\n",
    "\n",
    "text_file = open(report_path, \"w\")\n",
    "n = text_file.write(report)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a dictionary of label number and class\n",
    "df_original = pd.read_csv('Clean_dataset.csv')\n",
    "X = df_original[\"text\"].tolist()\n",
    "y = pd.get_dummies(df_original['label'])\n",
    "dict = {i: name for i, name in enumerate(y.columns)}\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the prediction based on three machine learning models\n",
    "def make_prediction(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    prediction_lr = lr.predict([cleaned_text])\n",
    "    prediction_svm = SVM.predict([cleaned_text])\n",
    "    prediction_nb =naivebayes.predict([cleaned_text])\n",
    "    return dict[prediction_lr[0]],dict[prediction_svm[0]],dict[prediction_nb[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"il n'y a plus de batterie\"\n",
    "make_prediction(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the three models\n",
    "LR_filename = './model/logistic_regression.sav'\n",
    "NB_filename = './model/Naive_bayes.sav'\n",
    "SVM_filename = './model/SVM.sav'\n",
    "joblib.dump(lr, LR_filename)\n",
    "joblib.dump(SVM, SVM_filename)\n",
    "joblib.dump(naivebayes, NB_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of three machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation of SVM:\")\n",
    "print(\"Mean absolute error\", mean_absolute_error(y_test, predictions_SVM))\n",
    "print(\"R2 Score\",r2_score(y_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation of Logistic Regression:\")\n",
    "print(\"Mean absolute error\", mean_absolute_error(y_test, predictions_LR))\n",
    "print(\"R2 Score\",r2_score(y_test, predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation of Naive Bayes:\")\n",
    "print(\"Mean absolute error\", mean_absolute_error(y_test, predictions_NB))\n",
    "print(\"R2 Score\",r2_score(y_test, predictions_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions_SVM,labels=SVM.classes_)\n",
    "print('Confusion Matrix\\n')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = df['label'].unique().sort(), \n",
    "                     columns = df['label'].unique().sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix for SVM Model')\n",
    "plt.ylabel('Actal Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f870e68b9436f49643135b35c4f835f13327db7ca6936246eabddb116e5747c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
