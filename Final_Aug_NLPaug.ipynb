{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "from nlpaug.util import Action\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Clean_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "num_classes = len(df[\"label\"].value_counts())\n",
    "\n",
    "colors = plt.cm.Dark2(np.linspace(0, 1, num_classes))\n",
    "iter_color = iter(colors)\n",
    "\n",
    "df['label'].value_counts().plot.barh(title=\"Reviews for each label (n, %)\", \n",
    "                                                 ylabel=\"labels\",\n",
    "                                                 color=colors,\n",
    "                                                 figsize=(9,9))\n",
    "\n",
    "for i, v in enumerate(df['label'].value_counts()):\n",
    "  c = next(iter_color)\n",
    "  plt.text(v, i,\n",
    "           \" \"+str(v)+\", \"+str(round(v*100/df.shape[0],2))+\"%\", \n",
    "           color=c, \n",
    "           va='center', \n",
    "           fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Textual labels to numeric using Label Encoder:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df[\"label2\"] = LabelEncoder().fit_transform(df[\"label\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig =df.groupby('label').count().reset_index()\n",
    "df_orig.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame augmented by translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_csv(\"data_after_translation.csv\")\n",
    "df_trans.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original data vs augmented data by translation\n",
    "df_aug =df_trans.groupby('label').count().reset_index()\n",
    "# Merge dataFrames\n",
    "data_df = pd.merge(df_orig, df_aug, on ='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "data_df = data_df.sort_values('text_x', ascending = True)\n",
    "#use fivethirty eights style of plots\n",
    "plt.style.use(\"fivethirtyeight\")#create the base axis to add the bars to\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,8))#extract the labels\n",
    "label = data_df[\"label\"]\n",
    "#use this to create x ticks to add the data to\n",
    "x = np.arange(len(label))#set a width for each bar \n",
    "width = 0.3#create out first bar\n",
    "#set it so that x will be the centre of the bars\n",
    "#so that we can add our labels later\n",
    "#so set the centre of the first to be 1/2 width away\n",
    "#to the left\n",
    "rect1 = ax.bar(x - width/2,\n",
    "              data_df[\"text_x\"],\n",
    "              width = width, \n",
    "               label = \"original\", color=\"red\",\n",
    "               edgecolor = \"white\"\n",
    "              )#create the second bar\n",
    "#with a centre half a width to the right\n",
    "rect2 = ax.bar(x + width/2,\n",
    "              data_df[\"text_y\"],\n",
    "              width = width,\n",
    "              label = \"translated\", color=\"blue\",\n",
    "              edgecolor = \"white\")#add the labels to the axis\n",
    "ax.set_ylabel(\"texts\",\n",
    "             fontsize = 10,\n",
    "             labelpad = 10)\n",
    "ax.set_xlabel(\"label\",\n",
    "             fontsize = 12,\n",
    "             labelpad =12)\n",
    "ax.set_title(\"Labels per class\",\n",
    "            fontsize = 12,\n",
    "            pad = 20)#set the ticks\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(label)#add the legend\n",
    "#using the labels of the bars\n",
    "ax.legend(title = \"Text\",\n",
    "         fontsize = 8,\n",
    "         title_fontsize = 20)#adjust the tick paramaters\n",
    "ax.tick_params(axis = \"x\",\n",
    "              which = \"both\", labelsize = 10,\n",
    "              labelrotation = 90)\n",
    "ax.tick_params(axis = \"y\", \n",
    "              which = \"both\",\n",
    "              labelsize = 8 )\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./df_augmented.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "num_classes = len(df[\"label\"].value_counts())\n",
    "\n",
    "colors = plt.cm.Dark2(np.linspace(0, 1, num_classes))\n",
    "iter_color = iter(colors)\n",
    "\n",
    "df['label'].value_counts().plot.barh(title=\"Reviews for each label (n, %)\", \n",
    "                                                 ylabel=\"labels\",\n",
    "                                                 color=colors,\n",
    "                                                 figsize=(9,9))\n",
    "\n",
    "for i, v in enumerate(df['label'].value_counts()):\n",
    "  c = next(iter_color)\n",
    "  plt.text(v, i,\n",
    "           \" \"+str(v)+\", \"+str(round(v*100/df.shape[0],2))+\"%\", \n",
    "           color=c, \n",
    "           va='center', \n",
    "           fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Textual labels to numeric using Label Encoder:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df[\"label2\"] = LabelEncoder().fit_transform(df[\"label\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =df.groupby('label2').count().reset_index()\n",
    "x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 3 texts\n",
    "df1 =x[x.text==3]\n",
    "list_3text = df1['label2'].tolist()\n",
    "list_3text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=7):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_3text      # list of classes with 3 texts \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary: augmented data \n",
    "aug_text1 = augment_text(df)\n",
    "aug_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 5 texts\n",
    "df2 =x[x.text==5]\n",
    "list_5text = df2['label2'].tolist()\n",
    "list_5text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data  \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=5):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_5text  # list of classes with 5 texts \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text2 = augment_text(df)\n",
    "#aug_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 6 texts\n",
    "df3 =x[x.text==6]\n",
    "list_6text = df3['label2'].tolist()\n",
    "list_6text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=4):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_6text      # list of classes with 6 texts \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text3 = augment_text(df)\n",
    "#aug_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 7 texts\n",
    "df4 =x[x.text==7]\n",
    "list_7text = df4['label2'].tolist()\n",
    "list_7text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=3):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_7text      # list of classes with 7 texts \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text4 = augment_text(df)\n",
    "#aug_text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 =x[x.text==9]\n",
    "list_9text = df5['label2'].tolist()\n",
    "list_9text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DICTIONARY \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=1):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_9text\n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text5 = augment_text(df)\n",
    "aug_text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text5)\n",
    "#print(aug_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dictionary into a dataframe\n",
    "df_augmented = pd.DataFrame(aug_text1.items(), columns=['text', 'label2'])\n",
    "#Add label \n",
    "df_augmented['translated'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented.drop_duplicates(inplace=True)\n",
    "df_augmented.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append dataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Textual labels to numeric using Label Encoder:\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#df[\"label2\"] = LabelEncoder().fit_transform(df[\"label\"])\n",
    "#Ordering the columns\n",
    "df = df[['text','label2','translated']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.append(df_augmented, ignore_index=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop_duplicates(inplace=True)\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myNLPaug')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20acd309b8488ca3010e43d9bbb80fa92cb5520871cecfe2aaa4969c71f4d6e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
