{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "from nlpaug.util import Action\n",
    "\n",
    "import re\n",
    "import string \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"  \", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "num_classes = len(df[\"label\"].value_counts())\n",
    "\n",
    "colors = plt.cm.Dark2(np.linspace(0, 1, num_classes))\n",
    "iter_color = iter(colors)\n",
    "\n",
    "df['label'].value_counts().plot.barh(title=\"Reviews for each label (n, %)\", \n",
    "                                                 ylabel=\"labels\",\n",
    "                                                 color=colors,\n",
    "                                                 figsize=(9,9))\n",
    "\n",
    "for i, v in enumerate(df['label'].value_counts()):\n",
    "  c = next(iter_color)\n",
    "  plt.text(v, i,\n",
    "           \" \"+str(v)+\", \"+str(round(v*100/df.shape[0],2))+\"%\", \n",
    "           color=c, \n",
    "           va='center', \n",
    "           fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Textual labels to numeric using Label Encoder:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df[\"label2\"] = LabelEncoder().fit_transform(df[\"label\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a labels map\n",
    "X = df[\"text\"].tolist()\n",
    "y = pd.get_dummies(df['label'])\n",
    "mapping = {i: name for i, name in enumerate(y.columns)}\n",
    "#mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "df_orig =df.groupby('label2').count().reset_index()  #label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame augmented by translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_csv(\"   \", sep=\";\")\n",
    "df_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_cleaner(text):\n",
    "    # remove numbers \n",
    "    text = ''.join(c for c in text if not c.isdigit())\n",
    "    # lower case \n",
    "    #text = \"\".join([i.lower() for i in text if i not in string.punctuation])\n",
    "    # remove any spaces\n",
    "    text = text.strip()\n",
    "    # remove any white spaces from beginning of string\n",
    "    text = text.lstrip() \n",
    "    # remove any white spaces from ending of string\n",
    "    text = text.rstrip()\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    #removing : \\ characters  from the text\n",
    "    text = re.sub(r'(:\\S+) | (\\\\S+)', r'', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans['text'] = df_trans['text'].apply(lambda x: texts_cleaner(x))\n",
    "df_trans['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and reset index\n",
    "df_trans = df_trans[['text', 'label', 'translated']]\n",
    "df_trans.drop_duplicates(inplace=True)\n",
    "df_trans = df_trans.reset_index(drop=True)\n",
    "df_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original data vs augmented data by translation\n",
    "df_aug_cleantrans =df_trans.groupby('label').count().reset_index()\n",
    "# Merge dataFrames\n",
    "data_df = pd.merge(df_orig, df_aug_cleantrans, on ='label')\n",
    "#data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "data_df = data_df.sort_values('text_y', ascending = True)\n",
    "#use fivethirty eights style of plots\n",
    "plt.style.use(\"fivethirtyeight\")#create the base axis to add the bars to\n",
    "fig, ax = plt.subplots(1,1, figsize = (12,8))#extract the labels\n",
    "label = data_df[\"label\"]\n",
    "#use this to create x ticks to add the data to\n",
    "x = np.arange(len(label))#set a width for each bar \n",
    "width = 0.3#create out first bar\n",
    "#set it so that x will be the centre of the bars\n",
    "#so that we can add our labels later\n",
    "#so set the centre of the first to be 1/2 width away\n",
    "#to the left\n",
    "rect1 = ax.bar(x - width/2,\n",
    "              data_df[\"text_x\"],\n",
    "              width = width, \n",
    "               label = \"original\", color=\"red\",\n",
    "               edgecolor = \"white\"\n",
    "              )#create the second bar\n",
    "#with a centre half a width to the right\n",
    "rect2 = ax.bar(x + width/2,\n",
    "              data_df[\"text_y\"],\n",
    "              width = width,\n",
    "              label = \"translated\", color=\"blue\",\n",
    "              edgecolor = \"white\")#add the labels to the axis\n",
    "ax.set_ylabel(\"texts\",\n",
    "             fontsize = 10,\n",
    "             labelpad = 10)\n",
    "ax.set_xlabel(\"label\",\n",
    "             fontsize = 12,\n",
    "             labelpad =12)\n",
    "ax.set_title(\"Labels per class after clean_translation\",\n",
    "            fontsize = 12,\n",
    "            pad = 20)#set the ticks\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(label)#add the legend\n",
    "#using the labels of the bars\n",
    "ax.legend(title = \"Text\",\n",
    "         fontsize = 8,\n",
    "         title_fontsize = 20)#adjust the tick paramaters\n",
    "ax.tick_params(axis = \"x\",\n",
    "              which = \"both\", labelsize = 10,\n",
    "              labelrotation = 90)\n",
    "ax.tick_params(axis = \"y\", \n",
    "              which = \"both\",\n",
    "              labelsize = 8 )\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_trans\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Textual labels to numeric using Label Encoder:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df[\"label2\"] = LabelEncoder().fit_transform(df[\"label\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select classes for the text augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 5 texts\n",
    "x =df.groupby('label2').count().reset_index()\n",
    "df1 =x[x.text==5]\n",
    "list_5text = df1['label2'].tolist()\n",
    "list_5text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=6):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_5text      # list of classes\n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary: augmented data \n",
    "aug_text1 = augment_text(df)\n",
    "aug_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 6 texts\n",
    "df2 =x[x.text==6]\n",
    "list_6text = df2['label2'].tolist()\n",
    "list_6text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data  \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=6):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_6text  # list of classes\n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text2 = augment_text(df)\n",
    "aug_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 7 texts  \n",
    "df3 =x[x.text==7]\n",
    "list_7text = df3['label2'].tolist()\n",
    "list_7text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=3):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_7text      # list of classes \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text3 = augment_text(df)\n",
    "aug_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select classes with 10 texts\n",
    "df4 =x[x.text==10]\n",
    "list_10text = df4['label2'].tolist()\n",
    "list_10text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=4):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_10text      # list of classes \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text4 = augment_text(df)\n",
    "aug_text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Select classes with 9 texts\n",
    "df5 =x[x.text==9]\n",
    "list_9text = df5['label2'].tolist()\n",
    "list_9text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Augmented data \n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#Augment French by BERT\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.2) #aug_p: Percentage of word will be augmented\n",
    "\n",
    "def augment_text(df,samples=5):\n",
    "    new_text=[]\n",
    "    label2 = []\n",
    "    res = {}\n",
    "    label = list_9text    # list of classes \n",
    "\n",
    "    for ii in label:\n",
    "        df_n=df[df.label2==ii].reset_index(drop=True)\n",
    "    \n",
    "        ## data augmentation loop\n",
    "        for i in tqdm(np.random.randint(0,len(df_n),samples)):\n",
    "        \n",
    "            text = df_n.iloc[i]['text']\n",
    "            label = df_n.iloc[i]['label2']\n",
    "            label2.append(label)\n",
    "            augmented_text = aug.augment(text)\n",
    "            new_text.append(augmented_text)\n",
    "\n",
    "        res = {new_text[i]: label2[i] for i in range(len(new_text))}\n",
    "  \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_text5 = augment_text(df)\n",
    "aug_text5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated dictionary\n",
    "aug_text1.update(aug_text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dictionary into a dataframe\n",
    "df_augmented = pd.DataFrame(aug_text1.items(), columns=['text', 'label2'])\n",
    "#Add label \n",
    "df_augmented['translated'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "df_augmented.drop_duplicates(inplace=True)\n",
    "df_augmented.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append dataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordering the columns\n",
    "df = df[['text','label2','translated']]\n",
    "#Append DataFrames\n",
    "df_final = df.append(df_augmented, ignore_index=True)\n",
    "df_final.drop_duplicates(inplace=True)\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('augmented_text.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myNLPaug')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20acd309b8488ca3010e43d9bbb80fa92cb5520871cecfe2aaa4969c71f4d6e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
